# CCTalker: When Compensatory Control Theory Meets 3D Emotional Talking Head Animation
The official repository of the paper [CCTalker: When Compensatory Control Theory Meets 3D Emotional Talking Head Animation](https://arxiv.org/abs/)

<p align='center'>
  <b>
    <a href="">Paper</a>
    | 
    <a href="http://nips25.github.io.bwbwiwn.site/">Project Page</a>
    |
    <a href="https://anonymous.4open.science/r/CCTalker-D626/README.md">Code</a> 
  </b>
</p> 

<!-- Colab notebook demonstration: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1Egq0_ZK5sJAAawShxC0y4JRZQuVS2X-Z?usp=sharing) -->

  <p align='center'>  
    <img src='/paper_images/CCTalker.png' width='1000'/>
  </p>

Given a speech signal as input, our framework <strong>CCTalker</strong> can generate realistic 3D talking head animtions through the Compensatory Control Theory <strong>(CCT)</strong> based diffusion processes.

## TODO
- [x] **Release Arxiv paper.**
- [x] **Release Project Page.**
- [ ] **Release code. (Once the paper is accepted)**
- [ ] **Release Pre-trained Model. (Once the paper is accepted)**



## Citation	

```
@article{2025cctalker,
  title={CCTalker: When Compensatory Control Theory Meets 3D Emotional Talking Head Animation},
  author={},
  year={2025},
  eprint={},
  archivePrefix={arXiv},
  primaryClass={cs.CV}
}
```


## Acknowledgement
<!-- Some code are borrowed from following projects:
* [ProbTalk3D](https://github.com/uuembodiedsocialai/ProbTalk3D/)
* [FaceDiffuser](https://github.com/uuembodiedsocialai/FaceDiffuser)
 -->

The README.md template is borrowed from [SyncTalk](https://github.com/ziqiaopeng/SyncTalk)


Thanks for these great projects.

